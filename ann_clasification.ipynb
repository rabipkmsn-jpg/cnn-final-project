{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmLIhVqLhUtZ",
        "outputId": "4fa12780-e342-4c32-d64e-1c6c88055560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 0us/step\n",
            "Training data shape: (50000, 32, 32, 3)\n",
            "Testing data shape: (10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets\n",
        "\n",
        "# 1. Load CIFAR-10 Dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# 2. Normalize pixel values to be between 0 and 1\n",
        "# ANN ke liye normalization bohat zaroori hai taake gradients stable rahein\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# 3. Class names for reference\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(f\"Training data shape: {train_images.shape}\")\n",
        "print(f\"Testing data shape: {test_images.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Split and Validation Setup\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "x_train_final, x_val, y_train_final, y_val = train_test_split(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Total Training Images: {len(x_train_final)}\")\n",
        "print(f\"Total Validation Images: {len(x_val)}\")\n",
        "print(f\"Total Test Images (Unseen): {len(test_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHYNMiQGh01g",
        "outputId": "e672d499-e229-4824-8dd3-f1cb97adad2a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Training Images: 40000\n",
            "Total Validation Images: 10000\n",
            "Total Test Images (Unseen): 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 2. ANN Model build\n",
        "def build_ann_baseline():\n",
        "    model = models.Sequential([\n",
        "        # convert Image 3D (32,32,3) to 1D\n",
        "        layers.Flatten(input_shape=(32, 32, 3)),\n",
        "\n",
        "        # Hidden Layers by using Relu\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "\n",
        "        # Output Layer (for 10 classes)\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Model compile\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 3. Model initialization\n",
        "ann_baseline = build_ann_baseline()\n",
        "\n",
        "# 4. Model trainning\n",
        "history_ann_a = ann_baseline.fit(\n",
        "    x_train_final,\n",
        "    y_train_final,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_data=(x_val, y_val)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JsOEnMmh4rZ",
        "outputId": "44e70619-1842-41a7-a371-232cf4d81e8d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.2705 - loss: 2.0186 - val_accuracy: 0.3620 - val_loss: 1.7528\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3803 - loss: 1.7292 - val_accuracy: 0.3901 - val_loss: 1.7242\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4239 - loss: 1.6124 - val_accuracy: 0.4336 - val_loss: 1.5847\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4509 - loss: 1.5520 - val_accuracy: 0.4423 - val_loss: 1.5521\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4606 - loss: 1.5092 - val_accuracy: 0.4445 - val_loss: 1.5542\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4745 - loss: 1.4697 - val_accuracy: 0.4520 - val_loss: 1.5412\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4824 - loss: 1.4404 - val_accuracy: 0.4581 - val_loss: 1.5257\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4973 - loss: 1.4092 - val_accuracy: 0.4819 - val_loss: 1.4503\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5056 - loss: 1.3762 - val_accuracy: 0.4771 - val_loss: 1.4812\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5139 - loss: 1.3640 - val_accuracy: 0.4896 - val_loss: 1.4689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# ANN  folders making\n",
        "os.makedirs('ann_results/models', exist_ok=True)\n",
        "os.makedirs('ann_results/reports', exist_ok=True)\n",
        "\n",
        "print(\"ANN folders 'models' and 'reports' are ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flQmgFH6imXy",
        "outputId": "728aa169-d5d5-4d87-8a77-cae255f42016"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN folders 'models' and 'reports' are ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scenario A model save\n",
        "ann_baseline.save('ann_results/models/ann_scenario_a_baseline.keras')\n",
        "print(\"Scenario A Model is saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfB-Zt4AmdlV",
        "outputId": "8b205c7e-5a90-4885-a3eb-c2f5509133c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scenario A Model is saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training results\n",
        "with open('ann_results/reports/ann_scenario_a_report.txt', 'w') as f:\n",
        "    f.write(\"ANN Scenario A: Baseline Report\\n\")\n",
        "    f.write(\"===============================\\n\")\n",
        "    f.write(f\"Final Training Accuracy: {history_ann_a.history['accuracy'][-1]:.4f}\\n\")\n",
        "    f.write(f\"Final Validation Accuracy: {history_ann_a.history['val_accuracy'][-1]:.4f}\\n\")\n",
        "    f.write(f\"Final Training Loss: {history_ann_a.history['loss'][-1]:.4f}\\n\")\n",
        "    f.write(f\"Final Validation Loss: {history_ann_a.history['val_loss'][-1]:.4f}\\n\")\n",
        "\n",
        "print(\"Scenario A Report is saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyG8MUkwmuio",
        "outputId": "44fb1896-d1c7-40d8-fad7-cea3e6b6495d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scenario A Report is saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report & Confusion Matrix Code\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# 1. Get model predictions on the validation set\n",
        "# Predict probability for each class\n",
        "y_pred_probs = ann_baseline.predict(x_val)\n",
        "\n",
        "# Convert probabilities to class labels (0 to 9)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# 2. Generate the Classification Report\n",
        "# This gives Precision, Recall, and F1-Score for every class\n",
        "report = classification_report(y_val, y_pred, target_names=class_names)\n",
        "\n",
        "print(\"ANN Scenario A: Classification Report\")\n",
        "print(\"======================================\")\n",
        "print(report)\n",
        "\n",
        "# 3. Save the report to a text file\n",
        "with open('ann_results/reports/ann_scenario_a_classification_report.txt', 'w') as f:\n",
        "    f.write(\"ANN Scenario A: Detailed Classification Report\\n\")\n",
        "    f.write(report)\n",
        "\n",
        "print(\"\\nReport saved to 'ann_results/reports/'\")"
      ],
      "metadata": {
        "id": "DJWo3scFm3AM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c002ab7-a202-4a70-b083-a3367158db4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "ANN Scenario A: Classification Report\n",
            "======================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.54      0.54      0.54       973\n",
            "  automobile       0.61      0.58      0.60       979\n",
            "        bird       0.41      0.37      0.39      1030\n",
            "         cat       0.34      0.44      0.38      1023\n",
            "        deer       0.47      0.36      0.41       933\n",
            "         dog       0.40      0.34      0.37      1015\n",
            "        frog       0.51      0.54      0.53       996\n",
            "       horse       0.55      0.54      0.55       994\n",
            "        ship       0.50      0.73      0.59      1017\n",
            "       truck       0.62      0.46      0.53      1040\n",
            "\n",
            "    accuracy                           0.49     10000\n",
            "   macro avg       0.50      0.49      0.49     10000\n",
            "weighted avg       0.50      0.49      0.49     10000\n",
            "\n",
            "\n",
            "Report saved to 'ann_results/reports/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN Scenario B: Optimized Learning Rate\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "def build_ann_scenario_b():\n",
        "    model = models.Sequential([\n",
        "        layers.Flatten(input_shape=(32, 32, 3)),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    # Learning rate 0.0001 (Default se 10x kam)\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "ann_model_b = build_ann_scenario_b()\n",
        "history_ann_b = ann_model_b.fit(x_train_final, y_train_final, epochs=10, batch_size=64, validation_data=(x_val, y_val))\n",
        "\n",
        "# Save for Scenario B\n",
        "ann_model_b.save('ann_results/models/ann_scenario_b_tuned.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvkkA9jtHbS0",
        "outputId": "72b3fa1b-2482-47d2-8420-cf47602686ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.2855 - loss: 1.9948 - val_accuracy: 0.3756 - val_loss: 1.7532\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3907 - loss: 1.7149 - val_accuracy: 0.4185 - val_loss: 1.6422\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4251 - loss: 1.6289 - val_accuracy: 0.4330 - val_loss: 1.5875\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4498 - loss: 1.5537 - val_accuracy: 0.4556 - val_loss: 1.5381\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4701 - loss: 1.5049 - val_accuracy: 0.4606 - val_loss: 1.5133\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4800 - loss: 1.4637 - val_accuracy: 0.4683 - val_loss: 1.4913\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4958 - loss: 1.4358 - val_accuracy: 0.4746 - val_loss: 1.4738\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5058 - loss: 1.3897 - val_accuracy: 0.4764 - val_loss: 1.4695\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5109 - loss: 1.3789 - val_accuracy: 0.4774 - val_loss: 1.4647\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5240 - loss: 1.3420 - val_accuracy: 0.4874 - val_loss: 1.4449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN Scenario C: Dropout + Augmentation\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_ann_scenario_c():\n",
        "    model = models.Sequential([\n",
        "        layers.Flatten(input_shape=(32, 32, 3)),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dropout(0.3),  # Adding Dropout\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "ann_model_c = build_ann_scenario_c()\n",
        "\n",
        "# Data Augmentation (Wahi jo CNN mein use ki thi)\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=15, horizontal_flip=True)\n",
        "\n",
        "print(\"Starting Optimized ANN Training...\")\n",
        "history_ann_c = ann_model_c.fit(datagen.flow(x_train_final, y_train_final, batch_size=64),\n",
        "                                 epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Save for Scenario C\n",
        "ann_model_c.save('ann_results/models/ann_scenario_c_optimized.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KJ3fue5Iz3a",
        "outputId": "2bfedf6f-5750-4af7-f438-1d7758e3b904"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Optimized ANN Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 37ms/step - accuracy: 0.1863 - loss: 2.1887 - val_accuracy: 0.2844 - val_loss: 1.9442\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - accuracy: 0.2726 - loss: 1.9609 - val_accuracy: 0.3206 - val_loss: 1.8480\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.2924 - loss: 1.9138 - val_accuracy: 0.3482 - val_loss: 1.8208\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.3053 - loss: 1.8813 - val_accuracy: 0.3430 - val_loss: 1.8240\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.3224 - loss: 1.8529 - val_accuracy: 0.3597 - val_loss: 1.7909\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.3299 - loss: 1.8402 - val_accuracy: 0.3716 - val_loss: 1.7448\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - accuracy: 0.3303 - loss: 1.8167 - val_accuracy: 0.3752 - val_loss: 1.7805\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.3295 - loss: 1.8259 - val_accuracy: 0.3769 - val_loss: 1.7272\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.3362 - loss: 1.8028 - val_accuracy: 0.3771 - val_loss: 1.7213\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.3449 - loss: 1.7967 - val_accuracy: 0.3852 - val_loss: 1.7357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# --- SAVE SCENARIO A ---\n",
        "ann_baseline.save('ann_results/models/ann_scenario_a_baseline.keras')\n",
        "with open('ann_results/reports/history_ann_a.pkl', 'wb') as f:\n",
        "    pickle.dump(history_ann_a.history, f)\n",
        "\n",
        "# --- SAVE SCENARIO B ---\n",
        "ann_model_b.save('ann_results/models/ann_scenario_b_tuned.keras')\n",
        "with open('ann_results/reports/history_ann_b.pkl', 'wb') as f:\n",
        "    pickle.dump(history_ann_b.history, f)\n",
        "\n",
        "# --- SAVE SCENARIO C ---\n",
        "ann_model_c.save('ann_results/models/ann_scenario_c_optimized.keras')\n",
        "with open('ann_results/reports/history_ann_c.pkl', 'wb') as f:\n",
        "    pickle.dump(history_ann_c.history, f)\n",
        "\n",
        "print(\"Success: Scenarios A, B, and C (Models & History) are all saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ6a239XI-Vf",
        "outputId": "a1427ce1-8330-4066-e4a1-d268d7fe673f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success: Scenarios A, B, and C (Models & History) are all saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Define the path and create folders first\n",
        "base_path = 'ann_outputs'\n",
        "os.makedirs(f'{base_path}/models', exist_ok=True)\n",
        "os.makedirs(f'{base_path}/histories', exist_ok=True)\n",
        "os.makedirs(f'{base_path}/plots', exist_ok=True)\n",
        "\n",
        "# 2. Define the plotting function (now it knows what base_path is)\n",
        "def save_final_plot(history_obj, name):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(history_obj.history['accuracy'], label='Train Acc')\n",
        "    plt.plot(history_obj.history['val_accuracy'], label='Val Acc')\n",
        "    plt.title(f'Results for {name}')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{base_path}/plots/{name}_plot.png')\n",
        "    plt.close()\n",
        "\n",
        "# 3. List of scenarios to save\n",
        "scenarios = [\n",
        "    ('ann_baseline', 'history_ann_a', 'scenario_a'),\n",
        "    ('ann_model_b', 'history_ann_b', 'scenario_b'),\n",
        "    ('ann_model_c', 'history_ann_c', 'scenario_c')\n",
        "]\n",
        "\n",
        "print(\"--- Starting the Saving Process ---\")\n",
        "\n",
        "# 4. Saving loop\n",
        "for model_var, hist_var, name in scenarios:\n",
        "    # Checking if the variables exist in Colab memory\n",
        "    if model_var in locals() and hist_var in locals():\n",
        "        model_obj = locals()[model_var]\n",
        "        hist_obj = locals()[hist_var]\n",
        "\n",
        "        # Save Model file\n",
        "        model_obj.save(f'{base_path}/models/{name}_model.keras')\n",
        "\n",
        "        # Save History Pickle file\n",
        "        with open(f'{base_path}/histories/{name}_history.pkl', 'wb') as f:\n",
        "            pickle.dump(hist_obj.history, f)\n",
        "\n",
        "        # Save the Plot\n",
        "        save_final_plot(hist_obj, name)\n",
        "\n",
        "        print(f\"âœ… {name.upper()} saved successfully.\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ {name.upper()} variables not found. Skipping...\")\n",
        "\n",
        "print(\"\\nAll available work is now saved in the 'ann_outputs' folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH110BHKKYHt",
        "outputId": "e41bb330-81f5-4b5b-b683-ed6cbdaabe28"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting the Saving Process ---\n",
            "âœ… SCENARIO_A saved successfully.\n",
            "âœ… SCENARIO_B saved successfully.\n",
            "âœ… SCENARIO_C saved successfully.\n",
            "\n",
            "All available work is now saved in the 'ann_outputs' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Zip the 'ann_outputs' folder into a single file\n",
        "shutil.make_archive('ann_final_submission', 'zip', 'ann_outputs')\n",
        "\n",
        "print(\"ğŸš€ 'ann_final_submission.zip' is ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-JC1AJzKZGR",
        "outputId": "f393d718-2042-4a2e-8b59-ff3e292294eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ 'ann_final_submission.zip' is ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gkCac2o4LEDt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}